{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MP4ToMP3(mp4: str, mp3: str) -> None:\n",
    "    \"\"\"Convert mp4 to mp3 using moviepy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mp4 : str\n",
    "        mp4 file path\n",
    "    mp3 : str\n",
    "        mp3 file path\n",
    "    \"\"\"\n",
    "    FILETOCONVERT = AudioFileClip(mp4)\n",
    "    FILETOCONVERT.write_audiofile(mp3)\n",
    "    FILETOCONVERT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ShortVideo.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "MP4ToMP3(\"ShortVideo.mov\", \"ShortVideo.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.95k/1.95k [00:00<00:00, 1.32MB/s]\n",
      "model.safetensors: 100%|██████████| 3.06G/3.06G [05:27<00:00, 9.34MB/s]\n",
      "generation_config.json: 100%|██████████| 1.92k/1.92k [00:00<00:00, 1.67MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 805/805 [00:00<00:00, 4.19MB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.78MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.41M/2.41M [00:01<00:00, 1.47MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.49MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 25.3MB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 7.62MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 1.83k/1.83k [00:00<00:00, 4.15MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "preprocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 9.78MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    model=\"openai/whisper-medium.en\",\n",
    "    chunk_length_s=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(14511) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "transcription = pipe(\"ShortVideo.mp3\", return_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" We used to do a lot of document understanding. This was my internship project a few ages ago. To understand handwriting in very difficult documents so that you can optimize processes in the back end. I have a background in computer vision, so I played a lot with mobile apps and previous hackathon challenges. I missed there. Previous hackathon challenges used to be around computer vision. You can do a lot of cool stuff with them. You can still do them today, but surprise, you don't have to do them manually. You can just ask the API to do it for you. And we do a lot, we used to do a lot of conversational interfaces. So 2017, when I came to Los Haca, I did chatbots and stuff. So this won't be the project for today. Okay? Okay, so I said a lot of used to used to used to. So what are we currently building? So we have two projects. One of them is computer board contracts, and the other one is understanding satellite images. The first one is how we can understand the law. How can we make computers understand law? Humans understand law, computers don't. Computers just text. So we can parse documents and text into a structured format which we call this computable contract and it has nothing to do with blockchain, don't think of that. It's just a suit of clauses, okay, that can help you then decide if something is covered, if something is talked about in a contract and if it is like an exclusion or if\",\n",
       " 'chunks': [{'timestamp': (0.0, 2.58),\n",
       "   'text': ' We used to do a lot of document understanding.'},\n",
       "  {'timestamp': (2.58, 5.28),\n",
       "   'text': ' This was my internship project a few ages ago.'},\n",
       "  {'timestamp': (5.84, 10.44),\n",
       "   'text': ' To understand handwriting in very difficult documents'},\n",
       "  {'timestamp': (10.44, 13.16),\n",
       "   'text': ' so that you can optimize processes in the back end.'},\n",
       "  {'timestamp': (14.28, 17.72),\n",
       "   'text': ' I have a background in computer vision, so I played a lot'},\n",
       "  {'timestamp': (17.78, 22.48),\n",
       "   'text': ' with mobile apps and previous hackathon challenges.'},\n",
       "  {'timestamp': (23.12, 23.72), 'text': ' I missed there.'},\n",
       "  {'timestamp': (24.06, 26.5),\n",
       "   'text': ' Previous hackathon challenges used to be around computer vision.'},\n",
       "  {'timestamp': (26.5, 28.5),\n",
       "   'text': ' You can do a lot of cool stuff with them.'},\n",
       "  {'timestamp': (28.5, 32.0),\n",
       "   'text': \" You can still do them today, but surprise, you don't have to do them manually.\"},\n",
       "  {'timestamp': (32.0, 35.0),\n",
       "   'text': ' You can just ask the API to do it for you.'},\n",
       "  {'timestamp': (35.0, 38.5),\n",
       "   'text': ' And we do a lot, we used to do a lot of conversational interfaces.'},\n",
       "  {'timestamp': (38.5, 42.0),\n",
       "   'text': ' So 2017, when I came to Los Haca, I did chatbots and stuff.'},\n",
       "  {'timestamp': (42.0, 46.24),\n",
       "   'text': \" So this won't be the project for today.\"},\n",
       "  {'timestamp': (46.24, 47.6), 'text': ' Okay?'},\n",
       "  {'timestamp': (47.6, 49.68),\n",
       "   'text': ' Okay, so I said a lot of used to used to used to.'},\n",
       "  {'timestamp': (49.68, 51.16), 'text': ' So what are we currently building?'},\n",
       "  {'timestamp': (51.16, 53.28), 'text': ' So we have two projects.'},\n",
       "  {'timestamp': (53.28, 55.52),\n",
       "   'text': ' One of them is computer board contracts,'},\n",
       "  {'timestamp': (55.52, 58.12),\n",
       "   'text': ' and the other one is understanding satellite images.'},\n",
       "  {'timestamp': (59.06, 61.8),\n",
       "   'text': ' The first one is how we can understand the law.'},\n",
       "  {'timestamp': (61.8, 63.82),\n",
       "   'text': ' How can we make computers understand law?'},\n",
       "  {'timestamp': (63.82, 69.0),\n",
       "   'text': \" Humans understand law, computers don't. Computers just text. So we can parse documents and\"},\n",
       "  {'timestamp': (69.0, 74.76),\n",
       "   'text': ' text into a structured format which we call this computable contract and it has'},\n",
       "  {'timestamp': (74.76, 78.96),\n",
       "   'text': \" nothing to do with blockchain, don't think of that. It's just a suit of\"},\n",
       "  {'timestamp': (78.96, 83.1),\n",
       "   'text': ' clauses, okay, that can help you then decide if something is covered, if'},\n",
       "  {'timestamp': (83.1, 86.6),\n",
       "   'text': ' something is talked about in a contract and if it is like an exclusion or if'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/6.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'ShortVideo.mov':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2023-12-02T14:42:31.000000Z\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: MacBookPro16,1\n",
      "    com.apple.quicktime.software: macOS 13.6 (22G120)\n",
      "    com.apple.quicktime.creationdate: 2023-12-02T11:03:07+0100\n",
      "  Duration: 00:01:29.59, start: 0.000000, bitrate: 14037 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 3572x2232 [SAR 1:1 DAR 893:558], 13844 kb/s, 59.33 fps, 60 tbr, 6k tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-12-02T14:42:31.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : H.264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 131 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-12-02T14:42:31.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> select:default\n",
      "  metadata:default -> Stream #0:0 (png)\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'scene_detection_output/frame%03d.png':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2023-12-02T11:03:07+0100\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: MacBookPro16,1\n",
      "    com.apple.quicktime.software: macOS 13.6 (22G120)\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0: Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 3572x2232 [SAR 1:1 DAR 893:558], q=2-31, 200 kb/s, 60 fps, 60 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 png\n",
      "frame=   14 fps=0.3 q=-0.0 Lsize=N/A time=00:01:00.31 bitrate=N/A speed=1.43x     s/s speed=N/A    \n",
      "video:39815kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_threshold = 0.03 # Lower => more sensitive\n",
    "input_video = \"ShortVideo.mov\"\n",
    "scene_detection_output = \"scene_detection_output\"\n",
    "os.makedirs(scene_detection_output, exist_ok=True)\n",
    "\n",
    "os.system(\n",
    "    f\"\"\"ffmpeg -i '{input_video}' -filter_complex \"select='gt(scene,{detection_threshold})',metadata=print:file='{scene_detection_output}/detected_frames.txt'\" -start_number 0 -fps_mode vfr {scene_detection_output}/frame%03d.png\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_ffmpeg_scene_detection_output(detected_frames_output: str) -> list[dict]:\n",
    "    # Read the text file\n",
    "    with open(detected_frames_output, \"r\") as file:\n",
    "        content = file.read()\n",
    "    # Extract frame numbers and pts_time numbers using regular expressions\n",
    "    frame_numbers = re.findall(r\"frame:(\\d+)\", content)\n",
    "    # pts_time_numbers = re.findall(r'pts_time:(\\d+\\.\\d+)', content)\n",
    "    pts_time_numbers = re.findall(r\"pts_time:(\\d+.\\d+)\", content)\n",
    "\n",
    "    return [\n",
    "        {\"frame_id\": int(frame_numbers[i]), \"pts_time\": float(pts_time_numbers[i])}\n",
    "        for i in range(len(frame_numbers))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>pts_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>35.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>51.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>60.3167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_id  pts_time\n",
       "0          0    1.2000\n",
       "3          3   15.0500\n",
       "4          4   35.8667\n",
       "7          7   51.0833\n",
       "13        13   60.3167"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_transition_df = pd.DataFrame(read_ffmpeg_scene_detection_output(\"scene_detection_output/detected_frames.txt\"))\n",
    "threshold = 1 # Number of seconds\n",
    "mask = (frame_transition_df['pts_time'].diff() > threshold).to_numpy()\n",
    "mask[0] = True\n",
    "frame_transition_df = frame_transition_df[mask]\n",
    "frame_transition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 2.58)</td>\n",
       "      <td>We used to do a lot of document understanding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2.58, 5.28)</td>\n",
       "      <td>This was my internship project a few ages ago.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5.84, 10.44)</td>\n",
       "      <td>To understand handwriting in very difficult d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.44, 13.16)</td>\n",
       "      <td>so that you can optimize processes in the bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(14.28, 17.72)</td>\n",
       "      <td>I have a background in computer vision, so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(17.78, 22.48)</td>\n",
       "      <td>with mobile apps and previous hackathon chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(23.12, 23.72)</td>\n",
       "      <td>I missed there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(24.06, 26.5)</td>\n",
       "      <td>Previous hackathon challenges used to be arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(26.5, 28.5)</td>\n",
       "      <td>You can do a lot of cool stuff with them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(28.5, 32.0)</td>\n",
       "      <td>You can still do them today, but surprise, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(32.0, 35.0)</td>\n",
       "      <td>You can just ask the API to do it for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(35.0, 38.5)</td>\n",
       "      <td>And we do a lot, we used to do a lot of conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(38.5, 42.0)</td>\n",
       "      <td>So 2017, when I came to Los Haca, I did chatb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(42.0, 46.24)</td>\n",
       "      <td>So this won't be the project for today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(46.24, 47.6)</td>\n",
       "      <td>Okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(47.6, 49.68)</td>\n",
       "      <td>Okay, so I said a lot of used to used to used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(49.68, 51.16)</td>\n",
       "      <td>So what are we currently building?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(51.16, 53.28)</td>\n",
       "      <td>So we have two projects.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(53.28, 55.52)</td>\n",
       "      <td>One of them is computer board contracts,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(55.52, 58.12)</td>\n",
       "      <td>and the other one is understanding satellite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(59.06, 61.8)</td>\n",
       "      <td>The first one is how we can understand the law.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(61.8, 63.82)</td>\n",
       "      <td>How can we make computers understand law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(63.82, 69.0)</td>\n",
       "      <td>Humans understand law, computers don't. Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(69.0, 74.76)</td>\n",
       "      <td>text into a structured format which we call t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(74.76, 78.96)</td>\n",
       "      <td>nothing to do with blockchain, don't think of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(78.96, 83.1)</td>\n",
       "      <td>clauses, okay, that can help you then decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(83.1, 86.6)</td>\n",
       "      <td>something is talked about in a contract and i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp                                               text\n",
       "0      (0.0, 2.58)     We used to do a lot of document understanding.\n",
       "1     (2.58, 5.28)     This was my internship project a few ages ago.\n",
       "2    (5.84, 10.44)   To understand handwriting in very difficult d...\n",
       "3   (10.44, 13.16)   so that you can optimize processes in the bac...\n",
       "4   (14.28, 17.72)   I have a background in computer vision, so I ...\n",
       "5   (17.78, 22.48)   with mobile apps and previous hackathon chall...\n",
       "6   (23.12, 23.72)                                    I missed there.\n",
       "7    (24.06, 26.5)   Previous hackathon challenges used to be arou...\n",
       "8     (26.5, 28.5)          You can do a lot of cool stuff with them.\n",
       "9     (28.5, 32.0)   You can still do them today, but surprise, yo...\n",
       "10    (32.0, 35.0)         You can just ask the API to do it for you.\n",
       "11    (35.0, 38.5)   And we do a lot, we used to do a lot of conve...\n",
       "12    (38.5, 42.0)   So 2017, when I came to Los Haca, I did chatb...\n",
       "13   (42.0, 46.24)            So this won't be the project for today.\n",
       "14   (46.24, 47.6)                                              Okay?\n",
       "15   (47.6, 49.68)   Okay, so I said a lot of used to used to used...\n",
       "16  (49.68, 51.16)                 So what are we currently building?\n",
       "17  (51.16, 53.28)                           So we have two projects.\n",
       "18  (53.28, 55.52)           One of them is computer board contracts,\n",
       "19  (55.52, 58.12)   and the other one is understanding satellite ...\n",
       "20   (59.06, 61.8)    The first one is how we can understand the law.\n",
       "21   (61.8, 63.82)          How can we make computers understand law?\n",
       "22   (63.82, 69.0)   Humans understand law, computers don't. Compu...\n",
       "23   (69.0, 74.76)   text into a structured format which we call t...\n",
       "24  (74.76, 78.96)   nothing to do with blockchain, don't think of...\n",
       "25   (78.96, 83.1)   clauses, okay, that can help you then decide ...\n",
       "26    (83.1, 86.6)   something is talked about in a contract and i..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_text_df = pd.DataFrame(transcription[\"chunks\"])\n",
    "time_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamps</th>\n",
       "      <th>slide_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.2)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.2, 15.05)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(15.05, 35.8667)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(35.8667, 51.0833)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(51.0833, 60.3167)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(60.3167, 86.6)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamps  slide_num\n",
       "0          (0.0, 1.2)          1\n",
       "1        (1.2, 15.05)          2\n",
       "2    (15.05, 35.8667)          3\n",
       "3  (35.8667, 51.0833)          4\n",
       "4  (51.0833, 60.3167)          5\n",
       "5     (60.3167, 86.6)          6"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_timestamps = ([0.0] + frame_transition_df[\"pts_time\"].tolist() + [time_text_df[\"timestamp\"].iloc[-1][-1]])\n",
    "slide_transitions = pd.DataFrame(\n",
    "    [\n",
    "        {\"timestamps\" : (start, end), \"slide_num\" : slide_num, } \n",
    "        for slide_num, (start, end) in enumerate(zip(slide_timestamps, slide_timestamps[1:]), start=1)\n",
    "    ]\n",
    ")\n",
    "slide_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio482",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
